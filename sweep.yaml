program: main.py
method: bayes #bayes
entity: dariusweber
name: sweep
metric:
  goal: minimize
  name: test_hybrid_gap
parameters:
  loss_weight_cons:
    max: 10
    min: 0.15
    distribution: uniform
  num_pred_layers:
    max: 4
    min: 3
    distribution: int_uniform
  loss_weight_obj:
    max: 10
    min: 0.15
    distribution: uniform
  num_mlp_layers:
    values: [2, 4]
    distribution: categorical
  loss_weight_x: #fix to 1
    max: 1.2
    min: 1
    distribution: uniform
  weight_decay: #0
    max: 0.00001
    min: 0.000000015
    distribution: uniform
  micro_batch: #1
    max: 4
    min: 1
    distribution: int_uniform
  ipm_steps: #8
    max: 8
    min: 4
    distribution: int_uniform
  ipm_alpha: #0.8
    max: 0.9
    min: 0.15
    distribution: uniform
  batchsize: #large as posible
    values: [512, 128, 80]
    distribution: categorical
  hidden:
    max: 360
    min: 90
    distribution: int_uniform
  runs: #1
    max: 3
    min: 1
    distribution: int_uniform
  conv:
    values:
      - ginconv
      - gcnconv
      - genconv
    distribution: categorical
  lr: #0.001
    max: 0.002
    min: 0.0005
    distribution: uniform
  datapath:
    values: ["../../../../work/log1/darius.weber/Quadratic_Programming_Datasets"]
    distribution: categorical

command:
  - ${python}
  - main.py
  - --datapath=${datapath}
  - --batchsize=${batchsize}
  - --conv=${conv}
  - --hidden=${hidden}
  - --ipm_alpha=${ipm_alpha}
  - --ipm_steps=${ipm_steps}
  - --loss_weight_cons=${loss_weight_cons}
  - --loss_weight_obj=${loss_weight_obj}
  - --loss_weight_x=${loss_weight_x}
  - --lr=${lr}
  - --micro_batch=${micro_batch}
  - --num_mlp_layers=${num_mlp_layers}
  - --num_pred_layers=${num_pred_layers}
  - --runs=${runs}
  - --weight_decay=${weight_decay}
